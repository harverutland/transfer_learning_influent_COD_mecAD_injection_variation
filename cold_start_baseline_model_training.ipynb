{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'libraries_imported' not in globals():\n",
    "    libraries_imported = False\n",
    "\n",
    "if libraries_imported == False:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import os\n",
    "    from datetime import datetime, timedelta\n",
    "    from datetime import datetime\n",
    "    # from scipy.interpolate import make_interp_splines\n",
    "    import plotly.graph_objects as go\n",
    "    from scipy.signal import butter, filtfilt\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense\n",
    "    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "    from keras_tuner import RandomSearch, HyperModel\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "    from keras_tuner import RandomSearch, HyperModel\n",
    "    from tensorflow.keras.layers import Input\n",
    "    import sys\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "    import joblib\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import joblib\n",
    "    import tensorflow as tf\n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import joblib\n",
    "    import tensorflow as tf\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import joblib\n",
    "    import os\n",
    "    from collections import Counter\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score, precision_recall_fscore_support,\n",
    "        confusion_matrix, ConfusionMatrixDisplay\n",
    "    )\n",
    "    from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "    # # Display the first few rows\n",
    "    # import ace_tools as tools  # Importing display tool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect Feature importances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic feature engineering -- Add mvoing averages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================\n",
    "# Setup portable directories\n",
    "# =============================\n",
    "BASE_DIR = Path.cwd()\n",
    "MODEL_DIR = BASE_DIR / \"model_params\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =============================\n",
    "# Load and prepare both datasets\n",
    "# =============================\n",
    "\n",
    "# # Dataset 1\n",
    "# dataset1_df = pd.read_csv(\"datasets/s_dataset1.csv\")\n",
    "# dataset1_df[\"date\"] = pd.to_datetime(dataset1_df['datetime'], format='%d.%m.%y')\n",
    "# dataset1_df.drop(columns=[\"index\", \"datetime\", \"f/m_ratio\", \"fos\", \"tac\"], inplace=True)\n",
    "# dataset1_df = dataset1_df.drop_duplicates()\n",
    "# dataset1_df[\"date\"] = pd.to_datetime(dataset1_df[\"date\"], dayfirst=True)\n",
    "\n",
    "# # Dataset 2\n",
    "# dataset2_df = pd.read_csv(\"datasets/c_dataset2.csv\")\n",
    "# dataset2_df['date'] = pd.to_datetime(dataset2_df['date'])\n",
    "# dataset2_df = dataset2_df.groupby('date').mean()\n",
    "# dataset2_df = dataset2_df.drop_duplicates()\n",
    "# dataset2_df.reset_index(inplace=True)\n",
    "# dataset2_df[\"methane_percentage\"] *= 100\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset 1\n",
    "# -----------------------------\n",
    "dataset1_df = pd.read_csv(\"datasets/s_dataset1.csv\")\n",
    "\n",
    "# Detect a date-like column\n",
    "candidates = [c for c in [\"datetime\", \"date\", \"day_number\"] if c in dataset1_df.columns]\n",
    "if not candidates:\n",
    "    raise ValueError(\"No 'date', 'datetime', or 'day_number' column found in dataset 1.\")\n",
    "src_col = candidates[0]\n",
    "\n",
    "# Build a clean 'date' column\n",
    "if src_col == \"day_number\":\n",
    "    base_date = pd.Timestamp(\"2020-01-01\")  # adjust as needed\n",
    "    dataset1_df[\"date\"] = base_date + pd.to_timedelta(dataset1_df[src_col], unit=\"D\")\n",
    "else:\n",
    "    dataset1_df[\"date\"] = pd.to_datetime(dataset1_df[src_col], dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "# Drop unwanted columns except the final 'date'\n",
    "cols_to_drop = [\"index\", \"f/m_ratio\", \"fos\", \"tac\"]\n",
    "dataset1_df.drop(columns=[c for c in cols_to_drop if c in dataset1_df.columns], inplace=True)\n",
    "\n",
    "if src_col != \"date\" and src_col in dataset1_df.columns:\n",
    "    dataset1_df.drop(columns=[src_col], inplace=True)\n",
    "\n",
    "dataset1_df = dataset1_df.drop_duplicates()\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset 2\n",
    "# -----------------------------\n",
    "dataset2_df = pd.read_csv(\"datasets/c_dataset2.csv\")\n",
    "\n",
    "# Detect a date-like column\n",
    "candidates = [c for c in [\"datetime\", \"date\", \"day_number\"] if c in dataset2_df.columns]\n",
    "if not candidates:\n",
    "    raise ValueError(\"No 'date', 'datetime', or 'day_number' column found in dataset 2.\")\n",
    "src_col = candidates[0]\n",
    "\n",
    "# Convert to datetime or compute from day_number\n",
    "if src_col == \"day_number\":\n",
    "    base_date = pd.Timestamp(\"2020-01-01\")  # adjust as needed\n",
    "    dataset2_df[\"date\"] = base_date + pd.to_timedelta(dataset2_df[src_col], unit=\"D\")\n",
    "else:\n",
    "    dataset2_df[\"date\"] = pd.to_datetime(dataset2_df[src_col], dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "# Group and clean\n",
    "dataset2_df = dataset2_df.groupby(\"date\").mean(numeric_only=True)\n",
    "dataset2_df = dataset2_df.drop_duplicates()\n",
    "dataset2_df.reset_index(inplace=True)\n",
    "\n",
    "# Scale methane percentage if present\n",
    "if \"methane_percentage\" in dataset2_df.columns:\n",
    "    dataset2_df[\"methane_percentage\"] *= 100\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[D1_p5] Artifacts already exist, skipping.\n",
      "[D2_p5] Artifacts already exist, skipping.\n",
      "[D1_p10] Artifacts already exist, skipping.\n",
      "[D2_p10] Artifacts already exist, skipping.\n",
      "[D1_p20] Artifacts already exist, skipping.\n",
      "[D2_p20] Artifacts already exist, skipping.\n",
      "[D1_p40] Artifacts already exist, skipping.\n",
      "[D2_p40] Artifacts already exist, skipping.\n",
      "[D1_p60] Artifacts already exist, skipping.\n",
      "[D2_p60] Artifacts already exist, skipping.\n",
      "[D1_p80] Skipping (keep_last_percent=80) → too few rows/classes after binning.\n",
      "[D2_p80] Artifacts already exist, skipping.\n",
      "[D1_p100] Skipping (keep_last_percent=100) → too few rows/classes after binning.\n",
      "[D2_p100] Artifacts already exist, skipping.\n",
      "\n",
      "Pretrain bank ready. Example paths:\n",
      " - transfer_learning_model_params/D1_p20/D1_p20_best_model.pkl\n",
      " - transfer_learning_model_params/D1_p20/D1_p20_scaler.pkl\n",
      " - transfer_learning_model_params/D2_p20/D2_p20_best_model.pkl\n",
      " - transfer_learning_model_params/D2_p20/D2_p20_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Imports\n",
    "# ------------------------------\n",
    "import os\n",
    "import random\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "\n",
    "# ------------------------------\n",
    "# Config\n",
    "# ------------------------------\n",
    "BASE_OUTDIR = \"transfer_learning_model_params\"   # all outputs go here\n",
    "os.makedirs(BASE_OUTDIR, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TARGET = \"eq_cod\"     # numeric target used for binning ONLY (NOT a feature)\n",
    "N_BINS = 4\n",
    "BIN_BASE = 500\n",
    "\n",
    "PARAM_GRID = {\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "}\n",
    "N_SPLITS = 3\n",
    "N_RANDOM_PARAM_ITER = 3\n",
    "\n",
    "DROP_COLUMNS_LIVE_ONLY = [\"h2s_ppm\", \"t1_cod\", \"t1_olr\", \"fostac\"]\n",
    "\n",
    "KEEP_LAST_PERCENT = 20  # default\n",
    "PRETRAIN_PERCENTS = [5, 10, 20, 40, 60, 80, 100]\n",
    "\n",
    "# ------------------------------\n",
    "# Reproducibility\n",
    "# ------------------------------\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# ------------------------------\n",
    "# Helpers\n",
    "# ------------------------------\n",
    "def round_to_nearest(x, base=500):\n",
    "    return int(base * round(float(x) / base))\n",
    "\n",
    "def random_param_sample(grid):\n",
    "    return {k: random.choice(v) for k, v in grid.items()}\n",
    "\n",
    "def ensure_columns(df, col_order):\n",
    "    df = df.copy()\n",
    "    for c in col_order:\n",
    "        if c not in df.columns:\n",
    "            df[c] = np.nan\n",
    "    extra = [c for c in df.columns if c not in col_order]\n",
    "    return df[col_order + extra]\n",
    "\n",
    "def keep_last_percent(df, percent, date_col=\"date\"):\n",
    "    df = df.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[date_col]).sort_values(date_col)\n",
    "\n",
    "    n_keep = int(np.ceil(len(df) * (percent / 100.0)))\n",
    "    n_keep = max(n_keep, 1)\n",
    "    return df.iloc[-n_keep:]\n",
    "\n",
    "def baseline_paths(dataset_tag):\n",
    "    outdir = os.path.join(BASE_OUTDIR, dataset_tag)\n",
    "    model_path  = os.path.join(outdir, f\"{dataset_tag}_best_model.pkl\")\n",
    "    scaler_path = os.path.join(outdir, f\"{dataset_tag}_scaler.pkl\")\n",
    "    feat_path   = os.path.join(outdir, f\"{dataset_tag}_feature_cols.pkl\")\n",
    "    bins_path   = os.path.join(outdir, f\"{dataset_tag}_bins.pkl\")\n",
    "    labels_path = os.path.join(outdir, f\"{dataset_tag}_labels.pkl\")\n",
    "    active_labels_path = os.path.join(outdir, f\"{dataset_tag}_active_labels.pkl\")\n",
    "    return outdir, model_path, scaler_path, feat_path, bins_path, labels_path, active_labels_path\n",
    "\n",
    "def artifacts_exist(dataset_tag):\n",
    "    _, model_path, scaler_path, feat_path, bins_path, labels_path, active_labels_path = baseline_paths(dataset_tag)\n",
    "    return all(os.path.exists(p) for p in [\n",
    "        model_path, scaler_path, feat_path, bins_path, labels_path, active_labels_path\n",
    "    ])\n",
    "\n",
    "def make_shared_bins(df_list, target_col, n_bins, base):\n",
    "    all_vals = pd.concat([df[target_col].dropna() for df in df_list], axis=0)\n",
    "    vmin, vmax = all_vals.min(), all_vals.max()\n",
    "\n",
    "    bins = np.linspace(vmin, vmax, n_bins + 1)\n",
    "    bins = [round_to_nearest(b, base) for b in bins]\n",
    "    bins[0] = min(bins[0], vmin)\n",
    "    bins[-1] = max(bins[-1], vmax)\n",
    "\n",
    "    if len(set(bins)) < len(bins):\n",
    "        base0 = round_to_nearest(vmin, base)\n",
    "        bins = [base0 + i * base for i in range(n_bins + 1)]\n",
    "\n",
    "    labels = [f\"{low}-{high}\" for low, high in zip(bins[:-1], bins[1:])]\n",
    "    return bins, labels\n",
    "\n",
    "def safe_train_test_split(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Stratify if possible (all classes have >=2 members); otherwise fallback\n",
    "    to non-stratified split.\n",
    "    \"\"\"\n",
    "    y_series = pd.Series(y)\n",
    "    counts = y_series.value_counts()\n",
    "    can_stratify = (counts.min() >= 2) and (len(counts) >= 2)\n",
    "\n",
    "    if can_stratify:\n",
    "        return train_test_split(\n",
    "            X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "        )\n",
    "\n",
    "    # fallback\n",
    "    return train_test_split(\n",
    "        X, y, test_size=test_size, stratify=None, random_state=random_state, shuffle=True\n",
    "    )\n",
    "\n",
    "# ------------------------------\n",
    "# Loaders / cleaners\n",
    "# ------------------------------\n",
    "def load_flex(path, *, aggregate=False, base_date=\"2020-01-01\",\n",
    "              methane_col=\"methane_percentage\", scale_methane=True):\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    src_col = next((c for c in [\"datetime\", \"date\", \"day_number\"] if c in df.columns), None)\n",
    "    if not src_col:\n",
    "        raise ValueError(f\"No date-like column found in {path}\")\n",
    "\n",
    "    df[\"date\"] = (\n",
    "        pd.Timestamp(base_date) + pd.to_timedelta(df[\"day_number\"], unit=\"D\")\n",
    "        if src_col == \"day_number\"\n",
    "        else pd.to_datetime(df[src_col], dayfirst=True, errors=\"coerce\")\n",
    "    )\n",
    "\n",
    "    if aggregate:\n",
    "        df = df.groupby(\"date\").mean(numeric_only=True).drop_duplicates().reset_index()\n",
    "    else:\n",
    "        drop_cols = [c for c in [\"index\", \"datetime\", \"day_number\", \"f/m_ratio\", \"fos\", \"tac\"]\n",
    "                     if c in df.columns]\n",
    "        df.drop(columns=drop_cols, inplace=True, errors=\"ignore\")\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "    if scale_methane and methane_col in df.columns:\n",
    "        df[methane_col] = df[methane_col] * 100\n",
    "\n",
    "    return df\n",
    "\n",
    "def harmonize_columns(sani_df, cook_df):\n",
    "    sani_cols = [\"date\"] + [c for c in sani_df.columns if c != \"date\"]\n",
    "    sani_df = sani_df.copy()\n",
    "    cook_df = ensure_columns(cook_df.copy(), sani_cols)\n",
    "\n",
    "    drop_sani = [c for c in DROP_COLUMNS_LIVE_ONLY if c in sani_df.columns]\n",
    "    drop_cook = [c for c in DROP_COLUMNS_LIVE_ONLY if c in cook_df.columns]\n",
    "    if drop_sani:\n",
    "        sani_df.drop(columns=drop_sani, inplace=True)\n",
    "    if drop_cook:\n",
    "        cook_df.drop(columns=drop_cook, inplace=True)\n",
    "    return sani_df, cook_df\n",
    "\n",
    "# ------------------------------\n",
    "# Core pipeline\n",
    "# ------------------------------\n",
    "def run_pipeline_for_dataset(df_raw, dataset_tag, *, shared_bins, shared_labels, keep_percent=None):\n",
    "\n",
    "    (\n",
    "        outdir, model_path, scaler_path, feat_path, bins_path, labels_path, active_labels_path\n",
    "    ) = baseline_paths(dataset_tag)\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    df = df_raw.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "    df.sort_values(\"date\", inplace=True)\n",
    "\n",
    "    kp = KEEP_LAST_PERCENT if keep_percent is None else keep_percent\n",
    "    df = keep_last_percent(df, kp, date_col=\"date\")\n",
    "\n",
    "    df = df.interpolate(method=\"ffill\").ffill()\n",
    "\n",
    "    if TARGET not in df.columns:\n",
    "        raise ValueError(f\"[{dataset_tag}] Target column '{TARGET}' not found.\")\n",
    "    df.dropna(subset=[TARGET], inplace=True)\n",
    "\n",
    "    # Shared binning\n",
    "    df[\"fostac_category\"] = pd.cut(\n",
    "        df[TARGET], bins=shared_bins, labels=shared_labels, include_lowest=True\n",
    "    )\n",
    "\n",
    "    df[\"fostac_category\"] = (\n",
    "        df[\"fostac_category\"]\n",
    "        .astype(\"category\")\n",
    "        .cat.set_categories(shared_labels, ordered=True)\n",
    "    )\n",
    "    df.dropna(subset=[\"fostac_category\"], inplace=True)\n",
    "\n",
    "    df[\"fostac_category\"] = df[\"fostac_category\"].cat.remove_unused_categories()\n",
    "    active_labels = list(df[\"fostac_category\"].cat.categories)\n",
    "\n",
    "    # X / y\n",
    "    X = df.select_dtypes(include=[np.number]).drop(columns=[TARGET])\n",
    "    y = df[\"fostac_category\"].cat.codes\n",
    "\n",
    "    assert TARGET not in X.columns, \"ERROR: eq_cod leaked into training features\"\n",
    "    feature_cols = list(X.columns)\n",
    "\n",
    "    # If we have too few rows overall, skip (avoid confusing partial artifacts)\n",
    "    if len(df) < 10 or len(np.unique(y)) < 2:\n",
    "        print(f\"[{dataset_tag}] Skipping (keep_last_percent={kp}) → too few rows/classes after binning.\")\n",
    "        return\n",
    "\n",
    "    # Train/test split (safe stratify)\n",
    "    X_train, X_test, y_train, y_test = safe_train_test_split(\n",
    "        X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    # Determine how many splits we can actually do\n",
    "    y_train_counts = pd.Series(y_train).value_counts()\n",
    "    min_class = int(y_train_counts.min()) if len(y_train_counts) else 0\n",
    "    n_splits_eff = min(N_SPLITS, min_class)\n",
    "\n",
    "    if n_splits_eff < 2:\n",
    "        # Not enough per-class samples for CV; train once with default params\n",
    "        final_scaler = RobustScaler()\n",
    "        X_train_scaled_full = final_scaler.fit_transform(X_train)\n",
    "\n",
    "        try:\n",
    "            sm = SMOTE(random_state=RANDOM_STATE, k_neighbors=2)\n",
    "            X_train_full_sm, y_train_full_sm = sm.fit_resample(X_train_scaled_full, y_train.astype(int))\n",
    "        except ValueError:\n",
    "            X_train_full_sm, y_train_full_sm = X_train_scaled_full, y_train.astype(int)\n",
    "\n",
    "        final_num_class = int(np.max(y_train_full_sm)) + 1\n",
    "\n",
    "        final_model = xgb.XGBClassifier(\n",
    "            objective=\"multi:softmax\",\n",
    "            num_class=final_num_class,\n",
    "            eval_metric=\"mlogloss\",\n",
    "            random_state=RANDOM_STATE,\n",
    "            **random_param_sample(PARAM_GRID)\n",
    "        )\n",
    "        final_model.fit(X_train_full_sm, y_train_full_sm)\n",
    "\n",
    "        joblib.dump(final_model, model_path)\n",
    "        joblib.dump(final_scaler, scaler_path)\n",
    "        joblib.dump(feature_cols, feat_path)\n",
    "        joblib.dump(shared_bins, bins_path)\n",
    "        joblib.dump(shared_labels, labels_path)\n",
    "        joblib.dump(active_labels, active_labels_path)\n",
    "\n",
    "        print(f\"[{dataset_tag}] Saved pretrained baseline (NO CV; keep_last_percent={kp}) → {outdir}\")\n",
    "        return\n",
    "\n",
    "    # Hyperparam search (CV)\n",
    "    skf = StratifiedKFold(n_splits=n_splits_eff, shuffle=True, random_state=RANDOM_STATE)\n",
    "    best_acc = -np.inf\n",
    "    best_params = None\n",
    "\n",
    "    for tr_idx, val_idx in skf.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[tr_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = pd.Series(y_train).iloc[tr_idx], pd.Series(y_train).iloc[val_idx]\n",
    "\n",
    "        # Shift fold labels to start at 0\n",
    "        y_tr_min = int(y_tr.min())\n",
    "        y_tr_shift = (y_tr - y_tr_min).astype(int)\n",
    "        y_val_shift = (y_val - y_tr_min).astype(int)\n",
    "\n",
    "        if not set(y_val_shift.unique()).issubset(set(y_tr_shift.unique())):\n",
    "            continue\n",
    "\n",
    "        scaler = RobustScaler()\n",
    "        X_tr_scaled = scaler.fit_transform(X_tr)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "        try:\n",
    "            sm = SMOTE(random_state=RANDOM_STATE, k_neighbors=2)\n",
    "            X_tr_sm, y_tr_sm = sm.fit_resample(X_tr_scaled, y_tr_shift)\n",
    "        except ValueError:\n",
    "            X_tr_sm, y_tr_sm = X_tr_scaled, y_tr_shift\n",
    "\n",
    "        fold_num_class = int(np.max(y_tr_sm)) + 1\n",
    "\n",
    "        for _ in range(N_RANDOM_PARAM_ITER):\n",
    "            params = random_param_sample(PARAM_GRID)\n",
    "            model = xgb.XGBClassifier(\n",
    "                objective=\"multi:softmax\",\n",
    "                num_class=fold_num_class,\n",
    "                eval_metric=\"mlogloss\",\n",
    "                random_state=RANDOM_STATE,\n",
    "                **params\n",
    "            )\n",
    "            model.fit(X_tr_sm, y_tr_sm)\n",
    "            acc = accuracy_score(y_val_shift, model.predict(X_val_scaled))\n",
    "\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_params = params\n",
    "\n",
    "    # Final train\n",
    "    final_scaler = RobustScaler()\n",
    "    X_train_scaled_full = final_scaler.fit_transform(X_train)\n",
    "\n",
    "    try:\n",
    "        sm = SMOTE(random_state=RANDOM_STATE, k_neighbors=2)\n",
    "        X_train_full_sm, y_train_full_sm = sm.fit_resample(\n",
    "            X_train_scaled_full, pd.Series(y_train).astype(int)\n",
    "        )\n",
    "    except ValueError:\n",
    "        X_train_full_sm, y_train_full_sm = X_train_scaled_full, pd.Series(y_train).astype(int)\n",
    "\n",
    "    final_num_class = int(np.max(y_train_full_sm)) + 1\n",
    "\n",
    "    final_model = xgb.XGBClassifier(\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=final_num_class,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        random_state=RANDOM_STATE,\n",
    "        **(best_params or random_param_sample(PARAM_GRID))\n",
    "    )\n",
    "    final_model.fit(X_train_full_sm, y_train_full_sm)\n",
    "\n",
    "    # Save artifacts\n",
    "    joblib.dump(final_model, model_path)\n",
    "    joblib.dump(final_scaler, scaler_path)\n",
    "    joblib.dump(feature_cols, feat_path)\n",
    "    joblib.dump(shared_bins, bins_path)\n",
    "    joblib.dump(shared_labels, labels_path)\n",
    "    joblib.dump(active_labels, active_labels_path)\n",
    "\n",
    "    print(f\"[{dataset_tag}] Saved pretrained baseline (keep_last_percent={kp}) → {outdir}\")\n",
    "\n",
    "# ------------------------------\n",
    "# Orchestrate both datasets + train multiple pretrain variants\n",
    "# ------------------------------\n",
    "dataset1_df = load_flex(\"datasets/s_dataset1.csv\")\n",
    "dataset2_df = load_flex(\"datasets/c_dataset2.csv\")\n",
    "\n",
    "dataset1_df, dataset2_df = harmonize_columns(dataset1_df, dataset2_df)\n",
    "\n",
    "# Shared bins/labels across BOTH full datasets (fixed reference)\n",
    "shared_bins, shared_labels = make_shared_bins([dataset1_df, dataset2_df], TARGET, N_BINS, BIN_BASE)\n",
    "\n",
    "# Train a bank of pretrained baselines at different injection percentages\n",
    "for pct in PRETRAIN_PERCENTS:\n",
    "    d1_tag = f\"D1_p{pct}\"\n",
    "    d2_tag = f\"D2_p{pct}\"\n",
    "\n",
    "    if artifacts_exist(d1_tag):\n",
    "        print(f\"[{d1_tag}] Artifacts already exist, skipping.\")\n",
    "    else:\n",
    "        run_pipeline_for_dataset(dataset1_df, d1_tag, shared_bins=shared_bins, shared_labels=shared_labels, keep_percent=pct)\n",
    "\n",
    "    if artifacts_exist(d2_tag):\n",
    "        print(f\"[{d2_tag}] Artifacts already exist, skipping.\")\n",
    "    else:\n",
    "        run_pipeline_for_dataset(dataset2_df, d2_tag, shared_bins=shared_bins, shared_labels=shared_labels, keep_percent=pct)\n",
    "\n",
    "print(\"\\nPretrain bank ready. Example paths:\")\n",
    "print(\" - transfer_learning_model_params/D1_p20/D1_p20_best_model.pkl\")\n",
    "print(\" - transfer_learning_model_params/D1_p20/D1_p20_scaler.pkl\")\n",
    "print(\" - transfer_learning_model_params/D2_p20/D2_p20_best_model.pkl\")\n",
    "print(\" - transfer_learning_model_params/D2_p20/D2_p20_scaler.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#############################################\n",
      "########## RANDOM_STATE = 1 ##########\n",
      "#############################################\n",
      "\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_scratch_rs1\n",
      "====================\n",
      "Best CV accuracy: 0.5455\n",
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 200, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.6643\n",
      "Hold-out MAE (bin steps):  0.4545\n",
      "Hold-out RMSE (bin steps): 0.8704\n",
      "Saved model → transfer_learning_model_params/baseline/D1_scratch_rs1/D1_scratch_rs1_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_scratch_rs1/D1_scratch_rs1_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_scratch_rs1/D1_scratch_rs1_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_scratch_rs1\n",
      "====================\n",
      "Best CV accuracy: 0.6190\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.01, 'n_estimators': 100, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.5633\n",
      "Hold-out MAE (bin steps):  0.5156\n",
      "Hold-out RMSE (bin steps): 0.9100\n",
      "Saved model → transfer_learning_model_params/baseline/D2_scratch_rs1/D2_scratch_rs1_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_scratch_rs1/D2_scratch_rs1_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_scratch_rs1/D2_scratch_rs1_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p5_rs1\n",
      "====================\n",
      "Best CV accuracy: 0.5606\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.05, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.6182\n",
      "Hold-out MAE (bin steps):  0.5455\n",
      "Hold-out RMSE (bin steps): 0.9535\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p5_rs1/D1_from_D2_p5_rs1_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p5_rs1/D1_from_D2_p5_rs1_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p5_rs1/D1_from_D2_p5_rs1_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p5_rs1\n",
      "====================\n",
      "Best CV accuracy: 0.6667\n",
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.1}\n",
      "Hold-out balanced accuracy:0.4456\n",
      "Hold-out MAE (bin steps):  0.7500\n",
      "Hold-out RMSE (bin steps): 1.1592\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p5_rs1/D2_from_D1_p5_rs1_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p5_rs1/D2_from_D1_p5_rs1_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p5_rs1/D2_from_D1_p5_rs1_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p10_rs1\n",
      "====================\n",
      "Best CV accuracy: 0.5606\n",
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.6300\n",
      "Hold-out MAE (bin steps):  0.5606\n",
      "Hold-out RMSE (bin steps): 0.9455\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p10_rs1/D1_from_D2_p10_rs1_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p10_rs1/D1_from_D2_p10_rs1_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p10_rs1/D1_from_D2_p10_rs1_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p10_rs1\n",
      "====================\n",
      "Best CV accuracy: 0.6508\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.4724\n",
      "Hold-out MAE (bin steps):  0.7500\n",
      "Hold-out RMSE (bin steps): 1.1990\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p10_rs1/D2_from_D1_p10_rs1_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p10_rs1/D2_from_D1_p10_rs1_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p10_rs1/D2_from_D1_p10_rs1_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p20_rs1\n",
      "====================\n",
      "Best CV accuracy: 0.5606\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.05, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.5876\n",
      "Hold-out MAE (bin steps):  0.5455\n",
      "Hold-out RMSE (bin steps): 0.9692\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p20_rs1/D1_from_D2_p20_rs1_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p20_rs1/D1_from_D2_p20_rs1_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p20_rs1/D1_from_D2_p20_rs1_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p20_rs1\n",
      "====================\n",
      "Best CV accuracy: 0.6508\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.1}\n",
      "Hold-out balanced accuracy:0.4229\n",
      "Hold-out MAE (bin steps):  0.7500\n",
      "Hold-out RMSE (bin steps): 1.1456\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p20_rs1/D2_from_D1_p20_rs1_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p20_rs1/D2_from_D1_p20_rs1_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p20_rs1/D2_from_D1_p20_rs1_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p40_rs1\n",
      "====================\n",
      "Best CV accuracy: 0.5606\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.05, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.6397\n",
      "Hold-out MAE (bin steps):  0.5152\n",
      "Hold-out RMSE (bin steps): 0.9535\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p40_rs1/D1_from_D2_p40_rs1_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p40_rs1/D1_from_D2_p40_rs1_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p40_rs1/D1_from_D2_p40_rs1_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p40_rs1\n",
      "====================\n",
      "Best CV accuracy: 0.6349\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.4229\n",
      "Hold-out MAE (bin steps):  0.7500\n",
      "Hold-out RMSE (bin steps): 1.1456\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p40_rs1/D2_from_D1_p40_rs1_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p40_rs1/D2_from_D1_p40_rs1_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p40_rs1/D2_from_D1_p40_rs1_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p60_rs1\n",
      "====================\n",
      "Best CV accuracy: 0.5606\n",
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.5656\n",
      "Hold-out MAE (bin steps):  0.6212\n",
      "Hold-out RMSE (bin steps): 1.0075\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p60_rs1/D1_from_D2_p60_rs1_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p60_rs1/D1_from_D2_p60_rs1_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p60_rs1/D1_from_D2_p60_rs1_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p60_rs1\n",
      "====================\n",
      "Best CV accuracy: 0.6508\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.4318\n",
      "Hold-out MAE (bin steps):  0.7344\n",
      "Hold-out RMSE (bin steps): 1.1388\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p60_rs1/D2_from_D1_p60_rs1_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p60_rs1/D2_from_D1_p60_rs1_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p60_rs1/D2_from_D1_p60_rs1_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p80_rs1\n",
      "====================\n",
      "Best CV accuracy: 0.5303\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.05, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 0.1}\n",
      "Hold-out balanced accuracy:0.5947\n",
      "Hold-out MAE (bin steps):  0.5000\n",
      "Hold-out RMSE (bin steps): 0.9129\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p80_rs1/D1_from_D2_p80_rs1_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p80_rs1/D1_from_D2_p80_rs1_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p80_rs1/D1_from_D2_p80_rs1_sensor_predictions_baseline.csv\n",
      "[SKIP] Missing pretrained artifacts for D1_p80\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p100_rs1\n",
      "====================\n",
      "Best CV accuracy: 0.5152\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.05, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.6260\n",
      "Hold-out MAE (bin steps):  0.5000\n",
      "Hold-out RMSE (bin steps): 0.9293\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p100_rs1/D1_from_D2_p100_rs1_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p100_rs1/D1_from_D2_p100_rs1_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p100_rs1/D1_from_D2_p100_rs1_sensor_predictions_baseline.csv\n",
      "[SKIP] Missing pretrained artifacts for D1_p100\n",
      "\n",
      "\n",
      "#############################################\n",
      "########## RANDOM_STATE = 7 ##########\n",
      "#############################################\n",
      "\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_scratch_rs7\n",
      "====================\n",
      "Best CV accuracy: 0.5758\n",
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.05, 'n_estimators': 200, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.7090\n",
      "Hold-out MAE (bin steps):  0.4697\n",
      "Hold-out RMSE (bin steps): 0.9129\n",
      "Saved model → transfer_learning_model_params/baseline/D1_scratch_rs7/D1_scratch_rs7_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_scratch_rs7/D1_scratch_rs7_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_scratch_rs7/D1_scratch_rs7_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_scratch_rs7\n",
      "====================\n",
      "Best CV accuracy: 0.7143\n",
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.1, 'n_estimators': 200, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.7227\n",
      "Hold-out MAE (bin steps):  0.2969\n",
      "Hold-out RMSE (bin steps): 0.5995\n",
      "Saved model → transfer_learning_model_params/baseline/D2_scratch_rs7/D2_scratch_rs7_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_scratch_rs7/D2_scratch_rs7_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_scratch_rs7/D2_scratch_rs7_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p5_rs7\n",
      "====================\n",
      "Best CV accuracy: 0.5758\n",
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.7431\n",
      "Hold-out MAE (bin steps):  0.4848\n",
      "Hold-out RMSE (bin steps): 0.9535\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p5_rs7/D1_from_D2_p5_rs7_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p5_rs7/D1_from_D2_p5_rs7_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p5_rs7/D1_from_D2_p5_rs7_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p5_rs7\n",
      "====================\n",
      "Best CV accuracy: 0.5079\n",
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.7024\n",
      "Hold-out MAE (bin steps):  0.3750\n",
      "Hold-out RMSE (bin steps): 0.7500\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p5_rs7/D2_from_D1_p5_rs7_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p5_rs7/D2_from_D1_p5_rs7_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p5_rs7/D2_from_D1_p5_rs7_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p10_rs7\n",
      "====================\n",
      "Best CV accuracy: 0.6061\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.05, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0.1}\n",
      "Hold-out balanced accuracy:0.6938\n",
      "Hold-out MAE (bin steps):  0.5606\n",
      "Hold-out RMSE (bin steps): 1.0372\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p10_rs7/D1_from_D2_p10_rs7_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p10_rs7/D1_from_D2_p10_rs7_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p10_rs7/D1_from_D2_p10_rs7_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p10_rs7\n",
      "====================\n",
      "Best CV accuracy: 0.4921\n",
      "Best hyperparameters: {'max_depth': 5, 'learning_rate': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.6337\n",
      "Hold-out MAE (bin steps):  0.4219\n",
      "Hold-out RMSE (bin steps): 0.8004\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p10_rs7/D2_from_D1_p10_rs7_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p10_rs7/D2_from_D1_p10_rs7_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p10_rs7/D2_from_D1_p10_rs7_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p20_rs7\n",
      "====================\n",
      "Best CV accuracy: 0.5606\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.6881\n",
      "Hold-out MAE (bin steps):  0.5303\n",
      "Hold-out RMSE (bin steps): 1.0075\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p20_rs7/D1_from_D2_p20_rs7_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p20_rs7/D1_from_D2_p20_rs7_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p20_rs7/D1_from_D2_p20_rs7_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p20_rs7\n",
      "====================\n",
      "Best CV accuracy: 0.5397\n",
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.6328\n",
      "Hold-out MAE (bin steps):  0.4531\n",
      "Hold-out RMSE (bin steps): 0.8570\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p20_rs7/D2_from_D1_p20_rs7_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p20_rs7/D2_from_D1_p20_rs7_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p20_rs7/D2_from_D1_p20_rs7_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p40_rs7\n",
      "====================\n",
      "Best CV accuracy: 0.5758\n",
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.6604\n",
      "Hold-out MAE (bin steps):  0.5303\n",
      "Hold-out RMSE (bin steps): 0.9924\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p40_rs7/D1_from_D2_p40_rs7_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p40_rs7/D1_from_D2_p40_rs7_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p40_rs7/D1_from_D2_p40_rs7_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p40_rs7\n",
      "====================\n",
      "Best CV accuracy: 0.5238\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.6932\n",
      "Hold-out MAE (bin steps):  0.3281\n",
      "Hold-out RMSE (bin steps): 0.6250\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p40_rs7/D2_from_D1_p40_rs7_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p40_rs7/D2_from_D1_p40_rs7_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p40_rs7/D2_from_D1_p40_rs7_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p60_rs7\n",
      "====================\n",
      "Best CV accuracy: 0.5606\n",
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.7165\n",
      "Hold-out MAE (bin steps):  0.4848\n",
      "Hold-out RMSE (bin steps): 0.9692\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p60_rs7/D1_from_D2_p60_rs7_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p60_rs7/D1_from_D2_p60_rs7_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p60_rs7/D1_from_D2_p60_rs7_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p60_rs7\n",
      "====================\n",
      "Best CV accuracy: 0.5397\n",
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.05, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.6190\n",
      "Hold-out MAE (bin steps):  0.4844\n",
      "Hold-out RMSE (bin steps): 0.8927\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p60_rs7/D2_from_D1_p60_rs7_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p60_rs7/D2_from_D1_p60_rs7_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p60_rs7/D2_from_D1_p60_rs7_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p80_rs7\n",
      "====================\n",
      "Best CV accuracy: 0.5303\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.6806\n",
      "Hold-out MAE (bin steps):  0.5000\n",
      "Hold-out RMSE (bin steps): 0.9293\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p80_rs7/D1_from_D2_p80_rs7_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p80_rs7/D1_from_D2_p80_rs7_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p80_rs7/D1_from_D2_p80_rs7_sensor_predictions_baseline.csv\n",
      "[SKIP] Missing pretrained artifacts for D1_p80\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p100_rs7\n",
      "====================\n",
      "Best CV accuracy: 0.5758\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.6806\n",
      "Hold-out MAE (bin steps):  0.5000\n",
      "Hold-out RMSE (bin steps): 0.9293\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p100_rs7/D1_from_D2_p100_rs7_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p100_rs7/D1_from_D2_p100_rs7_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p100_rs7/D1_from_D2_p100_rs7_sensor_predictions_baseline.csv\n",
      "[SKIP] Missing pretrained artifacts for D1_p100\n",
      "\n",
      "\n",
      "#############################################\n",
      "########## RANDOM_STATE = 13 ##########\n",
      "#############################################\n",
      "\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_scratch_rs13\n",
      "====================\n",
      "Best CV accuracy: 0.6212\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.05, 'n_estimators': 200, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 0.1}\n",
      "Hold-out balanced accuracy:0.5803\n",
      "Hold-out MAE (bin steps):  0.4697\n",
      "Hold-out RMSE (bin steps): 0.8072\n",
      "Saved model → transfer_learning_model_params/baseline/D1_scratch_rs13/D1_scratch_rs13_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_scratch_rs13/D1_scratch_rs13_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_scratch_rs13/D1_scratch_rs13_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_scratch_rs13\n",
      "====================\n",
      "Best CV accuracy: 0.6508\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.01, 'n_estimators': 200, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.6167\n",
      "Hold-out MAE (bin steps):  0.5000\n",
      "Hold-out RMSE (bin steps): 0.8839\n",
      "Saved model → transfer_learning_model_params/baseline/D2_scratch_rs13/D2_scratch_rs13_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_scratch_rs13/D2_scratch_rs13_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_scratch_rs13/D2_scratch_rs13_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p5_rs13\n",
      "====================\n",
      "Best CV accuracy: 0.6515\n",
      "Best hyperparameters: {'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.6129\n",
      "Hold-out MAE (bin steps):  0.4545\n",
      "Hold-out RMSE (bin steps): 0.8165\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p5_rs13/D1_from_D2_p5_rs13_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p5_rs13/D1_from_D2_p5_rs13_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p5_rs13/D1_from_D2_p5_rs13_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p5_rs13\n",
      "====================\n",
      "Best CV accuracy: 0.6349\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.5252\n",
      "Hold-out MAE (bin steps):  0.6562\n",
      "Hold-out RMSE (bin steps): 1.0607\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p5_rs13/D2_from_D1_p5_rs13_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p5_rs13/D2_from_D1_p5_rs13_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p5_rs13/D2_from_D1_p5_rs13_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p10_rs13\n",
      "====================\n",
      "Best CV accuracy: 0.6212\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.6470\n",
      "Hold-out MAE (bin steps):  0.4697\n",
      "Hold-out RMSE (bin steps): 0.8616\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p10_rs13/D1_from_D2_p10_rs13_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p10_rs13/D1_from_D2_p10_rs13_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p10_rs13/D1_from_D2_p10_rs13_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p10_rs13\n",
      "====================\n",
      "Best CV accuracy: 0.5873\n",
      "Best hyperparameters: {'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.5821\n",
      "Hold-out MAE (bin steps):  0.5781\n",
      "Hold-out RMSE (bin steps): 0.9922\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p10_rs13/D2_from_D1_p10_rs13_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p10_rs13/D2_from_D1_p10_rs13_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p10_rs13/D2_from_D1_p10_rs13_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p20_rs13\n",
      "====================\n",
      "Best CV accuracy: 0.6667\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.6413\n",
      "Hold-out MAE (bin steps):  0.4091\n",
      "Hold-out RMSE (bin steps): 0.7687\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p20_rs13/D1_from_D2_p20_rs13_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p20_rs13/D1_from_D2_p20_rs13_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p20_rs13/D1_from_D2_p20_rs13_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p20_rs13\n",
      "====================\n",
      "Best CV accuracy: 0.5873\n",
      "Best hyperparameters: {'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.5408\n",
      "Hold-out MAE (bin steps):  0.6562\n",
      "Hold-out RMSE (bin steps): 1.0897\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p20_rs13/D2_from_D1_p20_rs13_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p20_rs13/D2_from_D1_p20_rs13_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p20_rs13/D2_from_D1_p20_rs13_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p40_rs13\n",
      "====================\n",
      "Best CV accuracy: 0.6364\n",
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.05, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.6053\n",
      "Hold-out MAE (bin steps):  0.5152\n",
      "Hold-out RMSE (bin steps): 0.9211\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p40_rs13/D1_from_D2_p40_rs13_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p40_rs13/D1_from_D2_p40_rs13_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p40_rs13/D1_from_D2_p40_rs13_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p40_rs13\n",
      "====================\n",
      "Best CV accuracy: 0.5714\n",
      "Best hyperparameters: {'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.5565\n",
      "Hold-out MAE (bin steps):  0.6406\n",
      "Hold-out RMSE (bin steps): 1.0680\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p40_rs13/D2_from_D1_p40_rs13_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p40_rs13/D2_from_D1_p40_rs13_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p40_rs13/D2_from_D1_p40_rs13_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p60_rs13\n",
      "====================\n",
      "Best CV accuracy: 0.6364\n",
      "Best hyperparameters: {'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.6053\n",
      "Hold-out MAE (bin steps):  0.5152\n",
      "Hold-out RMSE (bin steps): 0.9211\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p60_rs13/D1_from_D2_p60_rs13_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p60_rs13/D1_from_D2_p60_rs13_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p60_rs13/D1_from_D2_p60_rs13_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p60_rs13\n",
      "====================\n",
      "Best CV accuracy: 0.5873\n",
      "Best hyperparameters: {'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.5565\n",
      "Hold-out MAE (bin steps):  0.6406\n",
      "Hold-out RMSE (bin steps): 1.0825\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p60_rs13/D2_from_D1_p60_rs13_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p60_rs13/D2_from_D1_p60_rs13_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p60_rs13/D2_from_D1_p60_rs13_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p80_rs13\n",
      "====================\n",
      "Best CV accuracy: 0.6818\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.5826\n",
      "Hold-out MAE (bin steps):  0.5758\n",
      "Hold-out RMSE (bin steps): 0.9692\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p80_rs13/D1_from_D2_p80_rs13_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p80_rs13/D1_from_D2_p80_rs13_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p80_rs13/D1_from_D2_p80_rs13_sensor_predictions_baseline.csv\n",
      "[SKIP] Missing pretrained artifacts for D1_p80\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p100_rs13\n",
      "====================\n",
      "Best CV accuracy: 0.6667\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.6356\n",
      "Hold-out MAE (bin steps):  0.5455\n",
      "Hold-out RMSE (bin steps): 0.9692\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p100_rs13/D1_from_D2_p100_rs13_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p100_rs13/D1_from_D2_p100_rs13_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p100_rs13/D1_from_D2_p100_rs13_sensor_predictions_baseline.csv\n",
      "[SKIP] Missing pretrained artifacts for D1_p100\n",
      "\n",
      "\n",
      "#############################################\n",
      "########## RANDOM_STATE = 42 ##########\n",
      "#############################################\n",
      "\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_scratch_rs42\n",
      "====================\n",
      "Best CV accuracy: 0.6061\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.1, 'n_estimators': 200, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 0.1}\n",
      "Hold-out balanced accuracy:0.7544\n",
      "Hold-out MAE (bin steps):  0.3333\n",
      "Hold-out RMSE (bin steps): 0.6963\n",
      "Saved model → transfer_learning_model_params/baseline/D1_scratch_rs42/D1_scratch_rs42_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_scratch_rs42/D1_scratch_rs42_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_scratch_rs42/D1_scratch_rs42_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_scratch_rs42\n",
      "====================\n",
      "Best CV accuracy: 0.5556\n",
      "Best hyperparameters: {'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 50, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0.1}\n",
      "Hold-out balanced accuracy:0.4707\n",
      "Hold-out MAE (bin steps):  0.6250\n",
      "Hold-out RMSE (bin steps): 1.0155\n",
      "Saved model → transfer_learning_model_params/baseline/D2_scratch_rs42/D2_scratch_rs42_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_scratch_rs42/D2_scratch_rs42_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_scratch_rs42/D2_scratch_rs42_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p5_rs42\n",
      "====================\n",
      "Best CV accuracy: 0.6515\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0.1}\n",
      "Hold-out balanced accuracy:0.7393\n",
      "Hold-out MAE (bin steps):  0.3636\n",
      "Hold-out RMSE (bin steps): 0.7177\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p5_rs42/D1_from_D2_p5_rs42_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p5_rs42/D1_from_D2_p5_rs42_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p5_rs42/D1_from_D2_p5_rs42_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p5_rs42\n",
      "====================\n",
      "Best CV accuracy: 0.5079\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.6044\n",
      "Hold-out MAE (bin steps):  0.6562\n",
      "Hold-out RMSE (bin steps): 1.0753\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p5_rs42/D2_from_D1_p5_rs42_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p5_rs42/D2_from_D1_p5_rs42_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p5_rs42/D2_from_D1_p5_rs42_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p10_rs42\n",
      "====================\n",
      "Best CV accuracy: 0.6061\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0.1}\n",
      "Hold-out balanced accuracy:0.7469\n",
      "Hold-out MAE (bin steps):  0.3485\n",
      "Hold-out RMSE (bin steps): 0.7071\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p10_rs42/D1_from_D2_p10_rs42_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p10_rs42/D1_from_D2_p10_rs42_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p10_rs42/D1_from_D2_p10_rs42_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p10_rs42\n",
      "====================\n",
      "Best CV accuracy: 0.5397\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.6149\n",
      "Hold-out MAE (bin steps):  0.6562\n",
      "Hold-out RMSE (bin steps): 1.0753\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p10_rs42/D2_from_D1_p10_rs42_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p10_rs42/D2_from_D1_p10_rs42_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p10_rs42/D2_from_D1_p10_rs42_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p20_rs42\n",
      "====================\n",
      "Best CV accuracy: 0.6061\n",
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.7620\n",
      "Hold-out MAE (bin steps):  0.3333\n",
      "Hold-out RMSE (bin steps): 0.7177\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p20_rs42/D1_from_D2_p20_rs42_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p20_rs42/D1_from_D2_p20_rs42_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p20_rs42/D1_from_D2_p20_rs42_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p20_rs42\n",
      "====================\n",
      "Best CV accuracy: 0.5397\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.5899\n",
      "Hold-out MAE (bin steps):  0.6562\n",
      "Hold-out RMSE (bin steps): 1.0753\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p20_rs42/D2_from_D1_p20_rs42_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p20_rs42/D2_from_D1_p20_rs42_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p20_rs42/D2_from_D1_p20_rs42_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p40_rs42\n",
      "====================\n",
      "Best CV accuracy: 0.6061\n",
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.5341\n",
      "Hold-out MAE (bin steps):  0.6364\n",
      "Hold-out RMSE (bin steps): 0.9692\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p40_rs42/D1_from_D2_p40_rs42_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p40_rs42/D1_from_D2_p40_rs42_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p40_rs42/D1_from_D2_p40_rs42_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p40_rs42\n",
      "====================\n",
      "Best CV accuracy: 0.5397\n",
      "Best hyperparameters: {'max_depth': 5, 'learning_rate': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 0.1}\n",
      "Hold-out balanced accuracy:0.5436\n",
      "Hold-out MAE (bin steps):  0.8281\n",
      "Hold-out RMSE (bin steps): 1.2562\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p40_rs42/D2_from_D1_p40_rs42_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p40_rs42/D2_from_D1_p40_rs42_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p40_rs42/D2_from_D1_p40_rs42_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p60_rs42\n",
      "====================\n",
      "Best CV accuracy: 0.6061\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.7110\n",
      "Hold-out MAE (bin steps):  0.3788\n",
      "Hold-out RMSE (bin steps): 0.7687\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p60_rs42/D1_from_D2_p60_rs42_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p60_rs42/D1_from_D2_p60_rs42_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p60_rs42/D1_from_D2_p60_rs42_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p60_rs42\n",
      "====================\n",
      "Best CV accuracy: 0.5238\n",
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.5801\n",
      "Hold-out MAE (bin steps):  0.6250\n",
      "Hold-out RMSE (bin steps): 1.0155\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p60_rs42/D2_from_D1_p60_rs42_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p60_rs42/D2_from_D1_p60_rs42_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p60_rs42/D2_from_D1_p60_rs42_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p80_rs42\n",
      "====================\n",
      "Best CV accuracy: 0.5909\n",
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.7393\n",
      "Hold-out MAE (bin steps):  0.3788\n",
      "Hold-out RMSE (bin steps): 0.7487\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p80_rs42/D1_from_D2_p80_rs42_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p80_rs42/D1_from_D2_p80_rs42_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p80_rs42/D1_from_D2_p80_rs42_sensor_predictions_baseline.csv\n",
      "[SKIP] Missing pretrained artifacts for D1_p80\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p100_rs42\n",
      "====================\n",
      "Best CV accuracy: 0.6212\n",
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0.2}\n",
      "Hold-out balanced accuracy:0.7393\n",
      "Hold-out MAE (bin steps):  0.3939\n",
      "Hold-out RMSE (bin steps): 0.7785\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p100_rs42/D1_from_D2_p100_rs42_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p100_rs42/D1_from_D2_p100_rs42_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p100_rs42/D1_from_D2_p100_rs42_sensor_predictions_baseline.csv\n",
      "[SKIP] Missing pretrained artifacts for D1_p100\n",
      "\n",
      "\n",
      "#############################################\n",
      "########## RANDOM_STATE = 99 ##########\n",
      "#############################################\n",
      "\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_scratch_rs99\n",
      "====================\n",
      "Best CV accuracy: 0.5455\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.05, 'n_estimators': 50, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.5179\n",
      "Hold-out MAE (bin steps):  0.5152\n",
      "Hold-out RMSE (bin steps): 0.8165\n",
      "Saved model → transfer_learning_model_params/baseline/D1_scratch_rs99/D1_scratch_rs99_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_scratch_rs99/D1_scratch_rs99_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_scratch_rs99/D1_scratch_rs99_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_scratch_rs99\n",
      "====================\n",
      "Best CV accuracy: 0.5873\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.6648\n",
      "Hold-out MAE (bin steps):  0.3594\n",
      "Hold-out RMSE (bin steps): 0.7603\n",
      "Saved model → transfer_learning_model_params/baseline/D2_scratch_rs99/D2_scratch_rs99_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_scratch_rs99/D2_scratch_rs99_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_scratch_rs99/D2_scratch_rs99_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p5_rs99\n",
      "====================\n",
      "Best CV accuracy: 0.5455\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.5262\n",
      "Hold-out MAE (bin steps):  0.5000\n",
      "Hold-out RMSE (bin steps): 0.8439\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p5_rs99/D1_from_D2_p5_rs99_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p5_rs99/D1_from_D2_p5_rs99_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p5_rs99/D1_from_D2_p5_rs99_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p5_rs99\n",
      "====================\n",
      "Best CV accuracy: 0.4921\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.5028\n",
      "Hold-out MAE (bin steps):  0.6875\n",
      "Hold-out RMSE (bin steps): 1.1180\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p5_rs99/D2_from_D1_p5_rs99_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p5_rs99/D2_from_D1_p5_rs99_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p5_rs99/D2_from_D1_p5_rs99_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p10_rs99\n",
      "====================\n",
      "Best CV accuracy: 0.5606\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.1}\n",
      "Hold-out balanced accuracy:0.5095\n",
      "Hold-out MAE (bin steps):  0.5000\n",
      "Hold-out RMSE (bin steps): 0.7882\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p10_rs99/D1_from_D2_p10_rs99_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p10_rs99/D1_from_D2_p10_rs99_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p10_rs99/D1_from_D2_p10_rs99_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p10_rs99\n",
      "====================\n",
      "Best CV accuracy: 0.4444\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.5549\n",
      "Hold-out MAE (bin steps):  0.6406\n",
      "Hold-out RMSE (bin steps): 1.0969\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p10_rs99/D2_from_D1_p10_rs99_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p10_rs99/D2_from_D1_p10_rs99_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p10_rs99/D2_from_D1_p10_rs99_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p20_rs99\n",
      "====================\n",
      "Best CV accuracy: 0.5455\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 0.1}\n",
      "Hold-out balanced accuracy:0.5167\n",
      "Hold-out MAE (bin steps):  0.5303\n",
      "Hold-out RMSE (bin steps): 0.8616\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p20_rs99/D1_from_D2_p20_rs99_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p20_rs99/D1_from_D2_p20_rs99_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p20_rs99/D1_from_D2_p20_rs99_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p20_rs99\n",
      "====================\n",
      "Best CV accuracy: 0.4921\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.5341\n",
      "Hold-out MAE (bin steps):  0.7031\n",
      "Hold-out RMSE (bin steps): 1.1792\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p20_rs99/D2_from_D1_p20_rs99_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p20_rs99/D2_from_D1_p20_rs99_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p20_rs99/D2_from_D1_p20_rs99_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p40_rs99\n",
      "====================\n",
      "Best CV accuracy: 0.5455\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 0.1}\n",
      "Hold-out balanced accuracy:0.5071\n",
      "Hold-out MAE (bin steps):  0.5152\n",
      "Hold-out RMSE (bin steps): 0.8348\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p40_rs99/D1_from_D2_p40_rs99_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p40_rs99/D1_from_D2_p40_rs99_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p40_rs99/D1_from_D2_p40_rs99_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p40_rs99\n",
      "====================\n",
      "Best CV accuracy: 0.4603\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.5265\n",
      "Hold-out MAE (bin steps):  0.7500\n",
      "Hold-out RMSE (bin steps): 1.2374\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p40_rs99/D2_from_D1_p40_rs99_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p40_rs99/D2_from_D1_p40_rs99_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p40_rs99/D2_from_D1_p40_rs99_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p60_rs99\n",
      "====================\n",
      "Best CV accuracy: 0.5455\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.5345\n",
      "Hold-out MAE (bin steps):  0.4091\n",
      "Hold-out RMSE (bin steps): 0.6629\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p60_rs99/D1_from_D2_p60_rs99_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p60_rs99/D1_from_D2_p60_rs99_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p60_rs99/D1_from_D2_p60_rs99_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D2_from_D1_p60_rs99\n",
      "====================\n",
      "Best CV accuracy: 0.4762\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.0}\n",
      "Hold-out balanced accuracy:0.5777\n",
      "Hold-out MAE (bin steps):  0.5938\n",
      "Hold-out RMSE (bin steps): 1.0308\n",
      "Saved model → transfer_learning_model_params/baseline/D2_from_D1_p60_rs99/D2_from_D1_p60_rs99_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D2_from_D1_p60_rs99/D2_from_D1_p60_rs99_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D2_from_D1_p60_rs99/D2_from_D1_p60_rs99_sensor_predictions_baseline.csv\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p80_rs99\n",
      "====================\n",
      "Best CV accuracy: 0.5455\n",
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 0.1}\n",
      "Hold-out balanced accuracy:0.4988\n",
      "Hold-out MAE (bin steps):  0.5303\n",
      "Hold-out RMSE (bin steps): 0.9129\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p80_rs99/D1_from_D2_p80_rs99_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p80_rs99/D1_from_D2_p80_rs99_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p80_rs99/D1_from_D2_p80_rs99_sensor_predictions_baseline.csv\n",
      "[SKIP] Missing pretrained artifacts for D1_p80\n",
      "\n",
      "====================\n",
      "Baseline (random split): D1_from_D2_p100_rs99\n",
      "====================\n",
      "Best CV accuracy: 0.5303\n",
      "Best hyperparameters: {'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0.1}\n",
      "Hold-out balanced accuracy:0.5417\n",
      "Hold-out MAE (bin steps):  0.4242\n",
      "Hold-out RMSE (bin steps): 0.7177\n",
      "Saved model → transfer_learning_model_params/baseline/D1_from_D2_p100_rs99/D1_from_D2_p100_rs99_baseline_model.pkl\n",
      "Saved scaler → transfer_learning_model_params/baseline/D1_from_D2_p100_rs99/D1_from_D2_p100_rs99_baseline_scaler.pkl\n",
      "Saved predictions → transfer_learning_model_params/baseline/D1_from_D2_p100_rs99/D1_from_D2_p100_rs99_sensor_predictions_baseline.csv\n",
      "[SKIP] Missing pretrained artifacts for D1_p100\n",
      "\n",
      "\n",
      "====================\n",
      "All runs (raw)\n",
      "====================\n",
      "                 run_tag  random_state  transfer  use_scaler pretrained_tag  \\\n",
      "0         D1_scratch_rs1             1     False       False                  \n",
      "1         D2_scratch_rs1             1     False       False                  \n",
      "2      D1_from_D2_p5_rs1             1      True        True          D2_p5   \n",
      "3      D2_from_D1_p5_rs1             1      True        True          D1_p5   \n",
      "4     D1_from_D2_p10_rs1             1      True        True         D2_p10   \n",
      "..                   ...           ...       ...         ...            ...   \n",
      "65   D2_from_D1_p40_rs99            99      True        True         D1_p40   \n",
      "66   D1_from_D2_p60_rs99            99      True        True         D2_p60   \n",
      "67   D2_from_D1_p60_rs99            99      True        True         D1_p60   \n",
      "68   D1_from_D2_p80_rs99            99      True        True         D2_p80   \n",
      "69  D1_from_D2_p100_rs99            99      True        True        D2_p100   \n",
      "\n",
      "    train_ratio  best_cv_acc  holdout_bacc  holdout_mae_bins  \\\n",
      "0           0.5     0.545455      0.664286          0.454545   \n",
      "1           0.5     0.619048      0.563312          0.515625   \n",
      "2           0.5     0.560606      0.618236          0.545455   \n",
      "3           0.5     0.666667      0.445617          0.750000   \n",
      "4           0.5     0.560606      0.629951          0.560606   \n",
      "..          ...          ...           ...               ...   \n",
      "65          0.5     0.460317      0.526515          0.750000   \n",
      "66          0.5     0.545455      0.534524          0.409091   \n",
      "67          0.5     0.476190      0.577652          0.593750   \n",
      "68          0.5     0.545455      0.498810          0.530303   \n",
      "69          0.5     0.530303      0.541667          0.424242   \n",
      "\n",
      "    holdout_rmse_bins dataset      mode  pretrain_pct  \n",
      "0            0.870388      D1   scratch           NaN  \n",
      "1            0.910014      D2   scratch           NaN  \n",
      "2            0.953463      D1  transfer           5.0  \n",
      "3            1.159202      D2  transfer           5.0  \n",
      "4            0.945484      D1  transfer          10.0  \n",
      "..                ...     ...       ...           ...  \n",
      "65           1.237437      D2  transfer          40.0  \n",
      "66           0.662868      D1  transfer          60.0  \n",
      "67           1.030776      D2  transfer          60.0  \n",
      "68           0.912871      D1  transfer          80.0  \n",
      "69           0.717741      D1  transfer         100.0  \n",
      "\n",
      "[70 rows x 13 columns]\n",
      "\n",
      "\n",
      "====================\n",
      "Scratch summary by dataset (mean/std/min/max)\n",
      "====================\n",
      "        holdout_bacc                               holdout_mae_bins            \\\n",
      "                mean       std       min       max             mean       std   \n",
      "dataset                                                                         \n",
      "D1          0.645168  0.095902  0.517857  0.754429         0.448485  0.068266   \n",
      "D2          0.607633  0.096568  0.470707  0.722707         0.459375  0.131008   \n",
      "\n",
      "                            holdout_rmse_bins                                \n",
      "              min       max              mean       std       min       max  \n",
      "dataset                                                                      \n",
      "D1       0.333333  0.515152          0.820646  0.081606  0.696311  0.912871  \n",
      "D2       0.296875  0.625000          0.833845  0.159402  0.599479  1.015505  \n",
      "\n",
      "\n",
      "====================\n",
      "Transfer summary by dataset + pretrained % (mean/std/min/max)\n",
      "====================\n",
      "                     holdout_bacc                                \\\n",
      "                             mean       std       min       max   \n",
      "dataset pretrain_pct                                              \n",
      "D1      5.0              0.647928  0.092634  0.526190  0.743056   \n",
      "        10.0             0.645422  0.088516  0.509524  0.746853   \n",
      "        20.0             0.639134  0.093753  0.516667  0.762005   \n",
      "        40.0             0.589323  0.066394  0.507143  0.660354   \n",
      "        60.0             0.626576  0.083461  0.534524  0.716540   \n",
      "        80.0             0.619188  0.093029  0.498810  0.739277   \n",
      "        100.0            0.644616  0.072938  0.541667  0.739277   \n",
      "D2      5.0              0.556099  0.099673  0.445617  0.702411   \n",
      "        10.0             0.571598  0.063161  0.472403  0.633682   \n",
      "        20.0             0.544095  0.078678  0.422890  0.632760   \n",
      "        40.0             0.548515  0.096531  0.422890  0.693152   \n",
      "        60.0             0.552991  0.071395  0.431818  0.618976   \n",
      "\n",
      "                     holdout_mae_bins                                \\\n",
      "                                 mean       std       min       max   \n",
      "dataset pretrain_pct                                                  \n",
      "D1      5.0                  0.469697  0.067760  0.363636  0.545455   \n",
      "        10.0                 0.487879  0.087302  0.348485  0.560606   \n",
      "        20.0                 0.469697  0.094013  0.333333  0.545455   \n",
      "        40.0                 0.542424  0.052922  0.515152  0.636364   \n",
      "        60.0                 0.481818  0.095467  0.378788  0.621212   \n",
      "        80.0                 0.496970  0.072979  0.378788  0.575758   \n",
      "        100.0                0.472727  0.061918  0.393939  0.545455   \n",
      "D2      5.0                  0.625000  0.144900  0.375000  0.750000   \n",
      "        10.0                 0.609375  0.121534  0.421875  0.750000   \n",
      "        20.0                 0.643750  0.113429  0.453125  0.750000   \n",
      "        40.0                 0.659375  0.196838  0.328125  0.828125   \n",
      "        60.0                 0.615625  0.090166  0.484375  0.734375   \n",
      "\n",
      "                     holdout_rmse_bins                                \n",
      "                                  mean       std       min       max  \n",
      "dataset pretrain_pct                                                  \n",
      "D1      5.0                   0.857007  0.099770  0.717741  0.953463  \n",
      "        10.0                  0.867918  0.129352  0.707107  1.037187  \n",
      "        20.0                  0.864972  0.124651  0.717741  1.007547  \n",
      "        40.0                  0.934212  0.061291  0.834847  0.992395  \n",
      "        60.0                  0.865895  0.145309  0.662868  1.007547  \n",
      "        80.0                  0.894604  0.084732  0.748736  0.969223  \n",
      "        100.0                 0.864821  0.109891  0.717741  0.969223  \n",
      "D2      5.0                   1.032637  0.162634  0.750000  1.159202  \n",
      "        10.0                  1.032733  0.149319  0.800391  1.198958  \n",
      "        20.0                  1.069373  0.125956  0.856957  1.179248  \n",
      "        40.0                  1.066463  0.258073  0.625000  1.256234  \n",
      "        60.0                  1.032059  0.091712  0.892679  1.138804  \n",
      "\n",
      "Saved aggregated run metrics → transfer_learning_model_params/baseline/run_summary_across_seeds_and_pretrain_pct.csv\n"
     ]
    }
   ],
   "source": [
    "# ===== Baseline (transfer learning + scaler switchable) =====\n",
    "# Random train/validation split (no temporal ordering)\n",
    "# Updated: loop over multiple pretrained variants (e.g., D1_p10, D1_p20, ...)\n",
    "\n",
    "import os, gc, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "\n",
    "# ------------------ Config ------------------\n",
    "OUTDIR_BASE = \"transfer_learning_model_params/baseline\"\n",
    "os.makedirs(OUTDIR_BASE, exist_ok=True)\n",
    "\n",
    "BASE_PRETRAIN_DIR = \"transfer_learning_model_params\"\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "RANDOM_STATES = [1, 7, 13, 42, 99]\n",
    "\n",
    "TARGET = \"eq_cod\"\n",
    "N_BINS = 4\n",
    "BIN_BASE = 500\n",
    "TRAIN_RATIO = 0.50\n",
    "CLASS_LABELS = [\"LL\", \"ML\", \"MH\", \"HH\"]\n",
    "\n",
    "# NEW: Pretrain variants to try (must exist on disk from your \"pretrain bank\" script)\n",
    "PRETRAIN_PERCENTS = [5, 10, 20, 40, 60, 80, 100]\n",
    "\n",
    "# ------------------ Switches ------------------\n",
    "ENABLE_TRANSFER_LEARNING = True\n",
    "ENABLE_PRETRAINED_SCALER = True\n",
    "ADDITIONAL_ESTIMATORS = 150\n",
    "\n",
    "if ENABLE_TRANSFER_LEARNING and not ENABLE_PRETRAINED_SCALER:\n",
    "    raise ValueError(\n",
    "        \"ENABLE_TRANSFER_LEARNING=True requires ENABLE_PRETRAINED_SCALER=True\"\n",
    "    )\n",
    "\n",
    "# ------------------ Helpers ------------------\n",
    "def round_to_nearest(x, base=500):\n",
    "    return int(base * round(float(x) / base))\n",
    "\n",
    "def random_param_sample(grid):\n",
    "    return {k: random.choice(v) for k, v in grid.items()}\n",
    "\n",
    "def build_design_matrix(df, feature_names):\n",
    "    cols = []\n",
    "    for name in feature_names:\n",
    "        if name in df.columns:\n",
    "            cols.append(df[name])\n",
    "        else:\n",
    "            cols.append(pd.Series(0.0, index=df.index, name=name))\n",
    "    return pd.concat(cols, axis=1)\n",
    "\n",
    "def bin_and_encode(df, target_col, n_bins=4, base=500, class_labels=None):\n",
    "    if class_labels is None:\n",
    "        class_labels = [\"LL\", \"ML\", \"MH\", \"HH\"]\n",
    "\n",
    "    vmin, vmax = df[target_col].min(), df[target_col].max()\n",
    "    bins = np.linspace(vmin, vmax, n_bins + 1)\n",
    "    bins = [round_to_nearest(b, base) for b in bins]\n",
    "    bins[0] = min(bins[0], vmin)\n",
    "    bins[-1] = max(bins[-1], vmax)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"target_label\"] = pd.cut(\n",
    "        df[target_col], bins=bins, labels=class_labels, include_lowest=True\n",
    "    )\n",
    "    df = df.dropna(subset=[\"target_label\"])\n",
    "    df[\"target_label\"] = (\n",
    "        df[\"target_label\"]\n",
    "        .astype(\"category\")\n",
    "        .cat.set_categories(class_labels, ordered=True)\n",
    "    )\n",
    "    return df, df[\"target_label\"].cat.codes, bins\n",
    "\n",
    "def prepare_df_for_baseline(raw_df, dayfirst=True):\n",
    "    df = raw_df.copy()\n",
    "    if \"date\" in df.columns:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\", dayfirst=dayfirst)\n",
    "    df = df.interpolate(method=\"ffill\").ffill()\n",
    "    return df.dropna(subset=[TARGET])\n",
    "\n",
    "def smote_safe(X, y, random_state=42):\n",
    "    y = pd.Series(y)\n",
    "    counts = Counter(y)\n",
    "    if not counts:\n",
    "        return X, y.values\n",
    "\n",
    "    maj = max(counts.values())\n",
    "    minority_counts = [c for c in counts.values() if c > 1]\n",
    "    min_count = min(minority_counts) if minority_counts else 0\n",
    "\n",
    "    k_neighbors = max(1, min(3, min_count - 1)) if min_count > 0 else 1\n",
    "    sampling_strategy = {cls: maj for cls, cnt in counts.items() if cnt > 1}\n",
    "\n",
    "    if sampling_strategy and min_count > 0:\n",
    "        sm = SMOTE(\n",
    "            random_state=random_state,\n",
    "            k_neighbors=k_neighbors,\n",
    "            sampling_strategy=sampling_strategy\n",
    "        )\n",
    "        return sm.fit_resample(X, y)\n",
    "\n",
    "    return X, y.values\n",
    "\n",
    "def pretrained_artifacts_exist(pretrained_tag):\n",
    "    pre_dir = os.path.join(BASE_PRETRAIN_DIR, pretrained_tag)\n",
    "    return (\n",
    "        os.path.exists(os.path.join(pre_dir, f\"{pretrained_tag}_best_model.pkl\")) and\n",
    "        os.path.exists(os.path.join(pre_dir, f\"{pretrained_tag}_scaler.pkl\")) and\n",
    "        os.path.exists(os.path.join(pre_dir, f\"{pretrained_tag}_feature_cols.pkl\"))\n",
    "    )\n",
    "\n",
    "def load_pretrained_artifacts(pretrained_tag):\n",
    "    pre_dir = os.path.join(BASE_PRETRAIN_DIR, pretrained_tag)\n",
    "\n",
    "    model = joblib.load(os.path.join(pre_dir, f\"{pretrained_tag}_best_model.pkl\"))\n",
    "    scaler = joblib.load(os.path.join(pre_dir, f\"{pretrained_tag}_scaler.pkl\"))\n",
    "    feature_cols = joblib.load(os.path.join(pre_dir, f\"{pretrained_tag}_feature_cols.pkl\"))\n",
    "\n",
    "    return model.get_booster(), scaler, feature_cols\n",
    "\n",
    "# ------------------ Baseline ------------------\n",
    "def baseline_direction(tgt_tag, tgt_df, pretrained_tag=None):\n",
    "    print(f\"\\n====================\")\n",
    "    print(f\"Baseline (random split): {tgt_tag}\")\n",
    "    print(f\"====================\")\n",
    "\n",
    "    random.seed(RANDOM_STATE)\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "\n",
    "    use_transfer = ENABLE_TRANSFER_LEARNING and (pretrained_tag is not None)\n",
    "    use_scaler   = ENABLE_PRETRAINED_SCALER and (pretrained_tag is not None)\n",
    "\n",
    "    booster = None\n",
    "    pretrained_scaler = None\n",
    "    pretrained_feature_cols = None\n",
    "\n",
    "    if use_transfer or use_scaler:\n",
    "        booster, pretrained_scaler, pretrained_feature_cols = load_pretrained_artifacts(\n",
    "            pretrained_tag\n",
    "        )\n",
    "\n",
    "    outdir = os.path.join(OUTDIR_BASE, tgt_tag)\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    model_path  = os.path.join(outdir, f\"{tgt_tag}_baseline_model.pkl\")\n",
    "    scaler_path = os.path.join(outdir, f\"{tgt_tag}_baseline_scaler.pkl\")\n",
    "    sensor_csv  = os.path.join(outdir, f\"{tgt_tag}_sensor_predictions_baseline.csv\")\n",
    "\n",
    "    # 1) Prepare + encode\n",
    "    df = prepare_df_for_baseline(tgt_df)\n",
    "    df, y_all, _ = bin_and_encode(df, TARGET, N_BINS, BIN_BASE, CLASS_LABELS)\n",
    "\n",
    "    if use_transfer or use_scaler:\n",
    "        feature_cols = pretrained_feature_cols\n",
    "    else:\n",
    "        feature_cols = [c for c in df.columns if c not in [\"date\", TARGET, \"target_label\"]]\n",
    "\n",
    "    X_all = build_design_matrix(df, feature_cols)\n",
    "\n",
    "    # ---- RANDOM SPLIT ----\n",
    "    rng = np.random.default_rng(RANDOM_STATE)\n",
    "    idx = rng.permutation(len(df))\n",
    "    train_size = int(TRAIN_RATIO * len(df))\n",
    "\n",
    "    train_idx = idx[:train_size]\n",
    "    val_idx   = idx[train_size:]\n",
    "\n",
    "    X_train_raw = X_all.iloc[train_idx].copy()\n",
    "    y_train     = y_all.iloc[train_idx].copy()\n",
    "\n",
    "    X_val_raw = X_all.iloc[val_idx].copy()\n",
    "    y_val     = y_all.iloc[val_idx].copy()\n",
    "\n",
    "    val_dates = df.iloc[val_idx][\"date\"]\n",
    "\n",
    "    # 2) Hyperparam search\n",
    "    if use_transfer:\n",
    "        param_grid = {\n",
    "            \"max_depth\": [3, 4, 5, 6],\n",
    "            \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "            \"subsample\": [0.8, 1.0],\n",
    "            \"colsample_bytree\": [0.8, 1.0],\n",
    "            \"gamma\": [0.0, 0.1, 0.2],\n",
    "        }\n",
    "    else:\n",
    "        param_grid = {\n",
    "            \"max_depth\": [3, 4, 5, 6],\n",
    "            \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"subsample\": [0.8, 1.0],\n",
    "            \"colsample_bytree\": [0.8, 1.0],\n",
    "            \"gamma\": [0.0, 0.1, 0.2],\n",
    "        }\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "    best_params, best_cv_acc = None, -np.inf\n",
    "\n",
    "    for _ in range(10):\n",
    "        params = random_param_sample(param_grid)\n",
    "        scores = []\n",
    "\n",
    "        for tr, va in skf.split(X_train_raw, y_train):\n",
    "            if use_scaler:\n",
    "                scaler = pretrained_scaler\n",
    "                X_tr = scaler.transform(X_train_raw.iloc[tr])\n",
    "                X_va = scaler.transform(X_train_raw.iloc[va])\n",
    "            else:\n",
    "                scaler = RobustScaler()\n",
    "                X_tr = scaler.fit_transform(X_train_raw.iloc[tr])\n",
    "                X_va = scaler.transform(X_train_raw.iloc[va])\n",
    "\n",
    "            X_tr_sm, y_tr_sm = smote_safe(X_tr, y_train.iloc[tr], RANDOM_STATE)\n",
    "\n",
    "            if use_transfer:\n",
    "                model = xgb.XGBClassifier(\n",
    "                    objective=\"multi:softmax\",\n",
    "                    num_class=len(CLASS_LABELS),\n",
    "                    eval_metric=\"mlogloss\",\n",
    "                    random_state=RANDOM_STATE,\n",
    "                    nthread=1,\n",
    "                    tree_method=\"hist\",\n",
    "                    n_estimators=ADDITIONAL_ESTIMATORS,\n",
    "                    **params\n",
    "                )\n",
    "                model.fit(X_tr_sm, y_tr_sm, xgb_model=booster)\n",
    "            else:\n",
    "                model = xgb.XGBClassifier(\n",
    "                    objective=\"multi:softmax\",\n",
    "                    num_class=len(CLASS_LABELS),\n",
    "                    eval_metric=\"mlogloss\",\n",
    "                    random_state=RANDOM_STATE,\n",
    "                    nthread=1,\n",
    "                    tree_method=\"hist\",\n",
    "                    **params\n",
    "                )\n",
    "                model.fit(X_tr_sm, y_tr_sm)\n",
    "\n",
    "            scores.append(accuracy_score(y_train.iloc[va], model.predict(X_va)))\n",
    "\n",
    "        mean_score = float(np.mean(scores))\n",
    "        if mean_score > best_cv_acc:\n",
    "            best_cv_acc = mean_score\n",
    "            best_params = params\n",
    "\n",
    "    print(f\"Best CV accuracy: {best_cv_acc:.4f}\")\n",
    "    print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "    # 3) Final train\n",
    "    if use_scaler:\n",
    "        scaler = pretrained_scaler\n",
    "        X_train_s = scaler.transform(X_train_raw)\n",
    "        X_val_s   = scaler.transform(X_val_raw)\n",
    "    else:\n",
    "        scaler = RobustScaler().fit(X_train_raw)\n",
    "        X_train_s = scaler.transform(X_train_raw)\n",
    "        X_val_s   = scaler.transform(X_val_raw)\n",
    "\n",
    "    X_train_sm, y_train_sm = smote_safe(X_train_s, y_train, RANDOM_STATE)\n",
    "\n",
    "    if use_transfer:\n",
    "        final_model = xgb.XGBClassifier(\n",
    "            objective=\"multi:softmax\",\n",
    "            num_class=len(CLASS_LABELS),\n",
    "            eval_metric=\"mlogloss\",\n",
    "            random_state=RANDOM_STATE,\n",
    "            nthread=1,\n",
    "            tree_method=\"hist\",\n",
    "            n_estimators=ADDITIONAL_ESTIMATORS,\n",
    "            **(best_params or {})\n",
    "        )\n",
    "        final_model.fit(X_train_sm, y_train_sm, xgb_model=booster)\n",
    "    else:\n",
    "        final_model = xgb.XGBClassifier(\n",
    "            objective=\"multi:softmax\",\n",
    "            num_class=len(CLASS_LABELS),\n",
    "            eval_metric=\"mlogloss\",\n",
    "            random_state=RANDOM_STATE,\n",
    "            nthread=1,\n",
    "            tree_method=\"hist\",\n",
    "            **(best_params or {})\n",
    "        )\n",
    "        final_model.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "    # 4) Evaluation (REDUCED METRICS)\n",
    "    y_pred = final_model.predict(X_val_s)\n",
    "\n",
    "    bacc = balanced_accuracy_score(y_val, y_pred)\n",
    "    mae_bins = float(np.mean(np.abs(y_val.values - y_pred)))\n",
    "    rmse_bins = float(np.sqrt(np.mean((y_val.values - y_pred) ** 2)))\n",
    "\n",
    "    print(f\"Hold-out balanced accuracy:{bacc:.4f}\")\n",
    "    print(f\"Hold-out MAE (bin steps):  {mae_bins:.4f}\")\n",
    "    print(f\"Hold-out RMSE (bin steps): {rmse_bins:.4f}\")\n",
    "\n",
    "    # 5) Save\n",
    "    sensor_df = pd.DataFrame({\n",
    "        \"date\": val_dates,\n",
    "        \"pred_bin_code\": y_pred,\n",
    "        \"pred_bin_label\": pd.Categorical(\n",
    "            y_pred, categories=[0, 1, 2, 3]\n",
    "        ).rename_categories(CLASS_LABELS).astype(str)\n",
    "    }).set_index(\"date\")\n",
    "\n",
    "    sensor_df.to_csv(sensor_csv)\n",
    "    joblib.dump(final_model, model_path)\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "\n",
    "    print(f\"Saved model → {model_path}\")\n",
    "    print(f\"Saved scaler → {scaler_path}\")\n",
    "    print(f\"Saved predictions → {sensor_csv}\")\n",
    "\n",
    "    del final_model\n",
    "    gc.collect()\n",
    "\n",
    "    return {\n",
    "        \"run_tag\": tgt_tag,\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "        \"transfer\": bool(use_transfer),\n",
    "        \"use_scaler\": bool(use_scaler),\n",
    "        \"pretrained_tag\": pretrained_tag if pretrained_tag is not None else \"\",\n",
    "        \"train_ratio\": TRAIN_RATIO,\n",
    "        \"best_cv_acc\": float(best_cv_acc),\n",
    "        \"holdout_bacc\": float(bacc),\n",
    "        \"holdout_mae_bins\": float(mae_bins),\n",
    "        \"holdout_rmse_bins\": float(rmse_bins),\n",
    "    }\n",
    "\n",
    "# ------------------ Run (vary RANDOM_STATE; try multiple pretrained variants) ------------------\n",
    "\n",
    "results = []\n",
    "\n",
    "# Always run scratch once per seed (reference), then sweep pretrained variants\n",
    "for rs in RANDOM_STATES:\n",
    "    RANDOM_STATE = rs\n",
    "\n",
    "    print(f\"\\n\\n#############################################\")\n",
    "    print(f\"########## RANDOM_STATE = {RANDOM_STATE} ##########\")\n",
    "    print(f\"#############################################\\n\")\n",
    "\n",
    "    # 1) NON-transfer (scratch)\n",
    "    ENABLE_TRANSFER_LEARNING = False\n",
    "    ENABLE_PRETRAINED_SCALER = False\n",
    "    results.append(baseline_direction(f\"D1_scratch_rs{rs}\", dataset1_df))\n",
    "    results.append(baseline_direction(f\"D2_scratch_rs{rs}\", dataset2_df))\n",
    "\n",
    "    # 2) Transfer learning: sweep over pretrain bank\n",
    "    ENABLE_TRANSFER_LEARNING = True\n",
    "    ENABLE_PRETRAINED_SCALER = True\n",
    "\n",
    "    for pct in PRETRAIN_PERCENTS:\n",
    "        d1_pre = f\"D1_p{pct}\"\n",
    "        d2_pre = f\"D2_p{pct}\"\n",
    "\n",
    "        # D1 target warm-started from D2 pretrain variant\n",
    "        if pretrained_artifacts_exist(d2_pre):\n",
    "            results.append(\n",
    "                baseline_direction(\n",
    "                    f\"D1_from_{d2_pre}_rs{rs}\",\n",
    "                    dataset1_df,\n",
    "                    pretrained_tag=d2_pre\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            print(f\"[SKIP] Missing pretrained artifacts for {d2_pre}\")\n",
    "\n",
    "        # D2 target warm-started from D1 pretrain variant\n",
    "        if pretrained_artifacts_exist(d1_pre):\n",
    "            results.append(\n",
    "                baseline_direction(\n",
    "                    f\"D2_from_{d1_pre}_rs{rs}\",\n",
    "                    dataset2_df,\n",
    "                    pretrained_tag=d1_pre\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            print(f\"[SKIP] Missing pretrained artifacts for {d1_pre}\")\n",
    "\n",
    "# ------------------ Summary stats (REDUCED) ------------------\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# dataset: D1/D2 target (from run_tag prefix)\n",
    "results_df[\"dataset\"] = results_df[\"run_tag\"].str.extract(r\"^(D1|D2)\")\n",
    "\n",
    "# mode: scratch/transfer\n",
    "results_df[\"mode\"] = np.where(results_df[\"transfer\"], \"transfer\", \"scratch\")\n",
    "\n",
    "# pretrain_pct: parse pXX from pretrained_tag if present\n",
    "results_df[\"pretrain_pct\"] = (\n",
    "    results_df[\"pretrained_tag\"]\n",
    "    .str.extract(r\"_p(\\d+)\")\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "print(\"\\n\\n====================\")\n",
    "print(\"All runs (raw)\")\n",
    "print(\"====================\")\n",
    "print(results_df)\n",
    "\n",
    "metrics = [\"holdout_bacc\", \"holdout_mae_bins\", \"holdout_rmse_bins\"]\n",
    "\n",
    "# Summaries:\n",
    "# 1) scratch baseline (per dataset)\n",
    "scratch_summary = (\n",
    "    results_df[results_df[\"mode\"] == \"scratch\"]\n",
    "    .groupby([\"dataset\"])[metrics]\n",
    "    .agg([\"mean\", \"std\", \"min\", \"max\"])\n",
    ")\n",
    "\n",
    "print(\"\\n\\n====================\")\n",
    "print(\"Scratch summary by dataset (mean/std/min/max)\")\n",
    "print(\"====================\")\n",
    "print(scratch_summary)\n",
    "\n",
    "# 2) transfer sweep (dataset + pretrain_pct)\n",
    "transfer_summary = (\n",
    "    results_df[results_df[\"mode\"] == \"transfer\"]\n",
    "    .groupby([\"dataset\", \"pretrain_pct\"])[metrics]\n",
    "    .agg([\"mean\", \"std\", \"min\", \"max\"])\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "print(\"\\n\\n====================\")\n",
    "print(\"Transfer summary by dataset + pretrained % (mean/std/min/max)\")\n",
    "print(\"====================\")\n",
    "print(transfer_summary)\n",
    "\n",
    "# Optional: save full results\n",
    "summary_csv = os.path.join(OUTDIR_BASE, \"run_summary_across_seeds_and_pretrain_pct.csv\")\n",
    "results_df.to_csv(summary_csv, index=False)\n",
    "print(f\"\\nSaved aggregated run metrics → {summary_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>pretrain_pct</th>\n",
       "      <th>BAcc (mean±std)</th>\n",
       "      <th>MAE bins (mean±std)</th>\n",
       "      <th>RMSE bins (mean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.648 ± 0.093</td>\n",
       "      <td>0.470 ± 0.068</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.645 ± 0.088</td>\n",
       "      <td>0.488 ± 0.087</td>\n",
       "      <td>0.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.639 ± 0.094</td>\n",
       "      <td>0.470 ± 0.094</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.589 ± 0.066</td>\n",
       "      <td>0.542 ± 0.053</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.627 ± 0.084</td>\n",
       "      <td>0.482 ± 0.096</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.619 ± 0.093</td>\n",
       "      <td>0.497 ± 0.073</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.645 ± 0.073</td>\n",
       "      <td>0.473 ± 0.062</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.556 ± 0.100</td>\n",
       "      <td>0.625 ± 0.145</td>\n",
       "      <td>1.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.572 ± 0.063</td>\n",
       "      <td>0.609 ± 0.121</td>\n",
       "      <td>1.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.544 ± 0.079</td>\n",
       "      <td>0.644 ± 0.113</td>\n",
       "      <td>1.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>D2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.548 ± 0.097</td>\n",
       "      <td>0.659 ± 0.197</td>\n",
       "      <td>1.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>D2</td>\n",
       "      <td>60</td>\n",
       "      <td>0.553 ± 0.071</td>\n",
       "      <td>0.616 ± 0.090</td>\n",
       "      <td>1.032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  pretrain_pct BAcc (mean±std) MAE bins (mean±std) RMSE bins (mean)\n",
       "0       D1             5   0.648 ± 0.093       0.470 ± 0.068            0.857\n",
       "1       D1            10   0.645 ± 0.088       0.488 ± 0.087            0.868\n",
       "2       D1            20   0.639 ± 0.094       0.470 ± 0.094            0.865\n",
       "3       D1            40   0.589 ± 0.066       0.542 ± 0.053            0.934\n",
       "4       D1            60   0.627 ± 0.084       0.482 ± 0.096            0.866\n",
       "5       D1            80   0.619 ± 0.093       0.497 ± 0.073            0.895\n",
       "6       D1           100   0.645 ± 0.073       0.473 ± 0.062            0.865\n",
       "7       D2             5   0.556 ± 0.100       0.625 ± 0.145            1.033\n",
       "8       D2            10   0.572 ± 0.063       0.609 ± 0.121            1.033\n",
       "9       D2            20   0.544 ± 0.079       0.644 ± 0.113            1.069\n",
       "10      D2            40   0.548 ± 0.097       0.659 ± 0.197            1.067\n",
       "11      D2            60   0.553 ± 0.071       0.616 ± 0.090            1.032"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "metrics = [\"holdout_bacc\", \"holdout_mae_bins\", \"holdout_rmse_bins\"]\n",
    "\n",
    "# transfer_summary is the one that includes ALL pretrained variants (dataset x pretrain_pct)\n",
    "# It was created like:\n",
    "# transfer_summary = results_df[results_df[\"mode\"]==\"transfer\"].groupby([\"dataset\",\"pretrain_pct\"])[metrics].agg([\"mean\",\"std\",\"min\",\"max\"])\n",
    "\n",
    "# 1) Flatten MultiIndex columns -> \"holdout_bacc_mean\", ...\n",
    "transfer_summary_flat = transfer_summary.copy()\n",
    "transfer_summary_flat.columns = [f\"{m}_{stat}\" for (m, stat) in transfer_summary_flat.columns]\n",
    "transfer_summary_flat = transfer_summary_flat.reset_index()\n",
    "\n",
    "# 2) Build a compact table\n",
    "refined = transfer_summary_flat.loc[:, [\n",
    "    \"dataset\", \"pretrain_pct\",\n",
    "    \"holdout_bacc_mean\", \"holdout_bacc_std\",\n",
    "    \"holdout_mae_bins_mean\", \"holdout_mae_bins_std\",\n",
    "    \"holdout_rmse_bins_mean\"\n",
    "]].copy()\n",
    "\n",
    "refined = refined.round(4)\n",
    "\n",
    "refined[\"BAcc (mean±std)\"] = refined[\"holdout_bacc_mean\"].map(lambda x: f\"{x:.3f}\") + \" ± \" + refined[\"holdout_bacc_std\"].map(lambda x: f\"{x:.3f}\")\n",
    "refined[\"MAE bins (mean±std)\"] = refined[\"holdout_mae_bins_mean\"].map(lambda x: f\"{x:.3f}\") + \" ± \" + refined[\"holdout_mae_bins_std\"].map(lambda x: f\"{x:.3f}\")\n",
    "refined[\"RMSE bins (mean)\"] = refined[\"holdout_rmse_bins_mean\"].map(lambda x: f\"{x:.3f}\")\n",
    "\n",
    "# nicer label for percent\n",
    "refined[\"pretrain_pct\"] = refined[\"pretrain_pct\"].astype(\"Int64\")\n",
    "\n",
    "refined = refined[[\"dataset\", \"pretrain_pct\", \"BAcc (mean±std)\", \"MAE bins (mean±std)\", \"RMSE bins (mean)\"]]\n",
    "refined = refined.sort_values([\"dataset\", \"pretrain_pct\"])\n",
    "\n",
    "display(refined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Scratch vs Best Transfer (per dataset) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>mode</th>\n",
       "      <th>pretrain_pct</th>\n",
       "      <th>BAcc (mean±std)</th>\n",
       "      <th>MAE bins (mean±std)</th>\n",
       "      <th>RMSE bins (mean±std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>scratch</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.645 ± 0.096</td>\n",
       "      <td>0.448 ± 0.068</td>\n",
       "      <td>0.821 ± 0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D1</td>\n",
       "      <td>transfer_best</td>\n",
       "      <td>5</td>\n",
       "      <td>0.648 ± 0.093</td>\n",
       "      <td>0.470 ± 0.068</td>\n",
       "      <td>0.857 ± 0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>scratch</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.608 ± 0.097</td>\n",
       "      <td>0.459 ± 0.131</td>\n",
       "      <td>0.834 ± 0.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D2</td>\n",
       "      <td>transfer_best</td>\n",
       "      <td>10</td>\n",
       "      <td>0.572 ± 0.063</td>\n",
       "      <td>0.609 ± 0.122</td>\n",
       "      <td>1.033 ± 0.149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset           mode  pretrain_pct BAcc (mean±std) MAE bins (mean±std)  \\\n",
       "0      D1        scratch          <NA>   0.645 ± 0.096       0.448 ± 0.068   \n",
       "2      D1  transfer_best             5   0.648 ± 0.093       0.470 ± 0.068   \n",
       "1      D2        scratch          <NA>   0.608 ± 0.097       0.459 ± 0.131   \n",
       "3      D2  transfer_best            10   0.572 ± 0.063       0.609 ± 0.122   \n",
       "\n",
       "  RMSE bins (mean±std)  \n",
       "0        0.821 ± 0.082  \n",
       "2        0.857 ± 0.100  \n",
       "1        0.834 ± 0.159  \n",
       "3        1.033 ± 0.149  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Deltas (Best Transfer - Scratch) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>best_pretrain_pct</th>\n",
       "      <th>delta_bacc</th>\n",
       "      <th>delta_mae_bins</th>\n",
       "      <th>delta_rmse_bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>5</td>\n",
       "      <td>+0.003</td>\n",
       "      <td>+0.021</td>\n",
       "      <td>+0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>+0.150</td>\n",
       "      <td>+0.199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  best_pretrain_pct delta_bacc delta_mae_bins delta_rmse_bins\n",
       "0      D1                  5     +0.003         +0.021          +0.036\n",
       "1      D2                 10     -0.036         +0.150          +0.199"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved → transfer_learning_model_params/baseline/scratch_vs_best_transfer.csv\n",
      "Saved → transfer_learning_model_params/baseline/scratch_vs_best_transfer_deltas.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Compare BEST transfer (by pretrain_pct) vs SCRATCH baseline\n",
    "# Assumes you already have a results_df with columns:\n",
    "#   - dataset (e.g. \"D1\",\"D2\")\n",
    "#   - mode (\"scratch\" or \"transfer\")\n",
    "#   - pretrain_pct (number for transfer rows; NaN for scratch rows is OK)\n",
    "#   - holdout_bacc, holdout_mae_bins, holdout_rmse_bins\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "OUTDIR_BASE = \"transfer_learning_model_params/baseline\"\n",
    "os.makedirs(OUTDIR_BASE, exist_ok=True)\n",
    "\n",
    "METRICS = [\"holdout_bacc\", \"holdout_mae_bins\", \"holdout_rmse_bins\"]\n",
    "\n",
    "def _mean_std(df, col):\n",
    "    return float(df[col].mean()), float(df[col].std(ddof=1)) if len(df) > 1 else (float(df[col].mean()), float(\"nan\"))\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Scratch summary (per dataset)\n",
    "# ---------------------------\n",
    "scratch_df = results_df[results_df[\"mode\"] == \"scratch\"].copy()\n",
    "\n",
    "scratch_summary = (\n",
    "    scratch_df\n",
    "    .groupby(\"dataset\")[METRICS]\n",
    "    .agg([\"mean\", \"std\", \"min\", \"max\"])\n",
    ")\n",
    "\n",
    "# Flatten columns -> holdout_bacc_mean, ...\n",
    "scratch_summary.columns = [f\"{m}_{stat}\" for (m, stat) in scratch_summary.columns]\n",
    "scratch_summary = scratch_summary.reset_index()\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Transfer summary (per dataset, pretrain_pct)\n",
    "# ---------------------------\n",
    "transfer_df = results_df[results_df[\"mode\"] == \"transfer\"].copy()\n",
    "\n",
    "# Ensure pretrain_pct is numeric\n",
    "transfer_df[\"pretrain_pct\"] = pd.to_numeric(transfer_df[\"pretrain_pct\"], errors=\"coerce\")\n",
    "\n",
    "transfer_summary = (\n",
    "    transfer_df\n",
    "    .dropna(subset=[\"pretrain_pct\"])\n",
    "    .groupby([\"dataset\", \"pretrain_pct\"])[METRICS]\n",
    "    .agg([\"mean\", \"std\", \"min\", \"max\"])\n",
    ")\n",
    "\n",
    "transfer_summary.columns = [f\"{m}_{stat}\" for (m, stat) in transfer_summary.columns]\n",
    "transfer_summary = transfer_summary.reset_index()\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Pick \"best transfer\" per dataset (highest mean BAcc)\n",
    "# ---------------------------\n",
    "best_transfer_idx = (\n",
    "    transfer_summary\n",
    "    .groupby(\"dataset\")[\"holdout_bacc_mean\"]\n",
    "    .idxmax()\n",
    ")\n",
    "\n",
    "best_transfer = transfer_summary.loc[best_transfer_idx].copy()\n",
    "best_transfer[\"mode\"] = \"transfer_best\"\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Build comparison table: scratch vs best transfer\n",
    "# ---------------------------\n",
    "scratch_comp = scratch_summary.copy()\n",
    "scratch_comp[\"pretrain_pct\"] = np.nan\n",
    "scratch_comp[\"mode\"] = \"scratch\"\n",
    "\n",
    "# Align columns\n",
    "cols_keep = [\n",
    "    \"dataset\", \"mode\", \"pretrain_pct\",\n",
    "    \"holdout_bacc_mean\", \"holdout_bacc_std\",\n",
    "    \"holdout_mae_bins_mean\", \"holdout_mae_bins_std\",\n",
    "    \"holdout_rmse_bins_mean\", \"holdout_rmse_bins_std\",\n",
    "]\n",
    "\n",
    "scratch_comp = scratch_comp.loc[:, cols_keep]\n",
    "best_transfer = best_transfer.loc[:, cols_keep]\n",
    "\n",
    "comparison = pd.concat([scratch_comp, best_transfer], ignore_index=True)\n",
    "\n",
    "# Nicely formatted strings\n",
    "comparison_fmt = comparison.copy()\n",
    "comparison_fmt[\"pretrain_pct\"] = comparison_fmt[\"pretrain_pct\"].astype(\"Int64\")\n",
    "\n",
    "comparison_fmt[\"BAcc (mean±std)\"] = (\n",
    "    comparison_fmt[\"holdout_bacc_mean\"].map(lambda x: f\"{x:.3f}\") +\n",
    "    \" ± \" +\n",
    "    comparison_fmt[\"holdout_bacc_std\"].map(lambda x: \"nan\" if pd.isna(x) else f\"{x:.3f}\")\n",
    ")\n",
    "\n",
    "comparison_fmt[\"MAE bins (mean±std)\"] = (\n",
    "    comparison_fmt[\"holdout_mae_bins_mean\"].map(lambda x: f\"{x:.3f}\") +\n",
    "    \" ± \" +\n",
    "    comparison_fmt[\"holdout_mae_bins_std\"].map(lambda x: \"nan\" if pd.isna(x) else f\"{x:.3f}\")\n",
    ")\n",
    "\n",
    "comparison_fmt[\"RMSE bins (mean±std)\"] = (\n",
    "    comparison_fmt[\"holdout_rmse_bins_mean\"].map(lambda x: f\"{x:.3f}\") +\n",
    "    \" ± \" +\n",
    "    comparison_fmt[\"holdout_rmse_bins_std\"].map(lambda x: \"nan\" if pd.isna(x) else f\"{x:.3f}\")\n",
    ")\n",
    "\n",
    "comparison_fmt = comparison_fmt.loc[:, [\n",
    "    \"dataset\", \"mode\", \"pretrain_pct\",\n",
    "    \"BAcc (mean±std)\", \"MAE bins (mean±std)\", \"RMSE bins (mean±std)\"\n",
    "]].sort_values([\"dataset\", \"mode\", \"pretrain_pct\"], na_position=\"first\")\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Also compute deltas (best transfer - scratch) per dataset\n",
    "# ---------------------------\n",
    "scratch_means = scratch_comp.set_index(\"dataset\")[[\"holdout_bacc_mean\", \"holdout_mae_bins_mean\", \"holdout_rmse_bins_mean\"]]\n",
    "best_means = best_transfer.set_index(\"dataset\")[[\"holdout_bacc_mean\", \"holdout_mae_bins_mean\", \"holdout_rmse_bins_mean\"]]\n",
    "\n",
    "delta = (best_means - scratch_means).reset_index()\n",
    "delta = delta.rename(columns={\n",
    "    \"holdout_bacc_mean\": \"delta_bacc\",\n",
    "    \"holdout_mae_bins_mean\": \"delta_mae_bins\",\n",
    "    \"holdout_rmse_bins_mean\": \"delta_rmse_bins\",\n",
    "})\n",
    "delta[\"delta_bacc\"] = delta[\"delta_bacc\"].map(lambda x: f\"{x:+.3f}\")\n",
    "delta[\"delta_mae_bins\"] = delta[\"delta_mae_bins\"].map(lambda x: f\"{x:+.3f}\")\n",
    "delta[\"delta_rmse_bins\"] = delta[\"delta_rmse_bins\"].map(lambda x: f\"{x:+.3f}\")\n",
    "\n",
    "# Add chosen best pct for context\n",
    "best_pct = best_transfer.set_index(\"dataset\")[\"pretrain_pct\"].astype(\"Int64\").rename(\"best_pretrain_pct\").reset_index()\n",
    "delta = delta.merge(best_pct, on=\"dataset\", how=\"left\")\n",
    "delta = delta[[\"dataset\", \"best_pretrain_pct\", \"delta_bacc\", \"delta_mae_bins\", \"delta_rmse_bins\"]].sort_values(\"dataset\")\n",
    "\n",
    "# ---------------------------\n",
    "# 6) Display + save\n",
    "# ---------------------------\n",
    "print(\"\\n=== Scratch vs Best Transfer (per dataset) ===\")\n",
    "display(comparison_fmt)\n",
    "\n",
    "print(\"\\n=== Deltas (Best Transfer - Scratch) ===\")\n",
    "display(delta)\n",
    "\n",
    "out_csv = os.path.join(OUTDIR_BASE, \"scratch_vs_best_transfer.csv\")\n",
    "comparison_fmt.to_csv(out_csv, index=False)\n",
    "print(f\"\\nSaved → {out_csv}\")\n",
    "\n",
    "out_csv2 = os.path.join(OUTDIR_BASE, \"scratch_vs_best_transfer_deltas.csv\")\n",
    "delta.to_csv(out_csv2, index=False)\n",
    "print(f\"Saved → {out_csv2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
